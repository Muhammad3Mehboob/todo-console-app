# Implementation Plan: Phase I - In-Memory Console App

**Branch**: `001-phase1-console-app` | **Date**: 2026-01-01 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `/specs/001-phase1-console-app/spec.md`

## Summary

Build a Python 3.13+ CLI todo application with in-memory storage, supporting five core operations: view tasks, add tasks, toggle completion, update tasks, and delete tasks. The application follows a clean modular architecture with separation of concerns (data model, business logic, CLI interface) to facilitate future evolution to persistent storage and web/API interfaces in subsequent phases.

## Technical Context

**Language/Version**: Python 3.13+
**Primary Dependencies**: Python standard library (dataclasses, datetime), pytest for testing
**Storage**: In-memory (Python list structure within TodoManager class)
**Testing**: pytest with 90% coverage target
**Target Platform**: Cross-platform CLI (Windows, macOS, Linux terminals)
**Project Type**: Single project (console application)
**Performance Goals**:
- View operations: <1 second for up to 1000 tasks
- Add/Update/Delete/Toggle operations: <100ms per operation
- Application startup: <500ms

**Constraints**:
- No external databases or file I/O
- Memory-only storage (data lost on exit)
- Single-user, single-session
- Must use UV for dependency management
- PEP 8 compliance mandatory

**Scale/Scope**:
- Support 1000+ tasks in memory
- Single Python package (~500 LOC)
- 4 core modules + entry point

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

### ✅ Principle I: AI-Native & Spec-Driven Development
- **Status**: PASS
- **Verification**: Following Specify → Plan → Tasks → Implement lifecycle
- **Evidence**: Spec created first at specs/001-phase1-console-app/spec.md with complete requirements

### ✅ Principle II: The Golden Rule - No Task = No Code
- **Status**: PASS
- **Verification**: No code will be written until tasks.md is created and approved
- **Evidence**: Currently in planning phase; implementation blocked until /sp.tasks completes

### ✅ Principle III: Single Source of Truth
- **Status**: PASS
- **Verification**: All requirements documented in spec.md, architecture in plan.md (this file)
- **Evidence**: Markdown specifications versioned in Git under specs/001-phase1-console-app/

### ✅ Principle IV: Iterative Evolution Through Phases
- **Status**: PASS
- **Verification**: This is Phase I (In-Memory Console App) as defined in constitution
- **Evidence**: Scope limited to console app, no database, no web/API (reserved for Phase II+)

### ✅ Principle V: No Manual Coding Mandate
- **Status**: PASS
- **Verification**: All code will be generated by Claude Code based on this plan and tasks
- **Evidence**: Planning workflow followed; awaiting task breakdown before code generation

### ✅ Principle VI: Strict Workflow Adherence
- **Status**: PASS
- **Verification**: Following Constitution → Specify → Plan → Tasks → Implement sequence
- **Evidence**: Constitution ratified (v1.0.0), spec created, now creating plan, PHRs generated

### ✅ Principle VII: Statelessness & Database Persistence
- **Status**: PASS
- **Verification**: In-memory storage prepares for stateless services in later phases
- **Evidence**: Architecture designed with TodoManager as isolated state holder, easily replaceable

### Technical Stack Compliance

✅ **Python 3.13+**: Required language/version
✅ **UV**: Package management specified
✅ **PEP 8**: Code style standard enforced
✅ **90% Test Coverage**: Success criteria SC-008 requires comprehensive testing
✅ **No External DB**: Phase I constraint (in-memory only)
✅ **CLI Application**: Matches Phase I requirements

**GATE RESULT**: ✅ **ALL CHECKS PASSED** - Proceed to Phase 0 Research

## Project Structure

### Documentation (this feature)

```text
specs/001-phase1-console-app/
├── spec.md              # Feature specification (completed)
├── plan.md              # This file (in progress)
├── research.md          # Phase 0 output (to be created)
├── data-model.md        # Phase 1 output (to be created)
├── quickstart.md        # Phase 1 output (to be created)
├── contracts/           # Phase 1 output (N/A for console app)
├── checklists/
│   └── requirements.md  # Spec quality checklist (completed)
└── tasks.md             # Phase 2 output (/sp.tasks command)
```

### Source Code (repository root)

```text
todo-console/
├── pyproject.toml       # UV project configuration
├── README.md            # Setup and usage instructions
├── .gitignore           # Python standard ignores
├── src/
│   └── todo_app/
│       ├── __init__.py       # Package init
│       ├── models.py         # Task data model (dataclass)
│       ├── manager.py        # TodoManager business logic
│       ├── cli.py            # CLI interface and command parsing
│       └── main.py           # Application entry point
└── tests/
    ├── __init__.py
    ├── unit/
    │   ├── test_models.py    # Task model unit tests
    │   ├── test_manager.py   # TodoManager unit tests
    │   └── test_cli.py       # CLI parsing unit tests
    └── integration/
        └── test_workflows.py # End-to-end workflow tests
```

**Structure Decision**:

Selected Option 1 (Single project) because:
- Phase I is a standalone console application
- No frontend/backend separation needed (no web interface)
- No API layer required in this phase
- Simple module structure facilitates easy transition to web app in Phase II
- Tests organized by type (unit vs integration) for clear separation of concerns

The `todo-console/` directory will be created at repository root, containing all Phase I code in a clean Python package structure following modern best practices (src layout with tests separate).

## Complexity Tracking

No constitutional violations detected. All gates passed without justification needed.

---

# Phase 0: Research & Technical Decisions

## Research Topics

### 1. Python CLI Best Practices

**Decision**: Use standard library `input()` with command loop pattern

**Rationale**:
- No external dependencies needed (aligns with simplicity principle)
- Direct control over input/output for testing
- Easy to understand and maintain
- Sufficient for Phase I requirements (no complex argument parsing needed)

**Alternatives Considered**:
- `argparse`: Overkill for interactive loop; better suited for one-shot commands
- `click`/`typer`: External dependencies add unnecessary complexity for Phase I
- `cmd` module: Adds structure but increases LOC without clear benefit

**References**:
- PEP 20 (Zen of Python): "Simple is better than complex"
- Spec requirement: Basic command-line interface, not complex CLI tool

### 2. In-Memory Data Structure Selection

**Decision**: Use Python `list[Task]` with integer counter for ID generation

**Rationale**:
- O(n) lookups acceptable for target scale (1000 tasks)
- Simple to implement and test
- Preserves insertion order (natural task list ordering)
- Easy to iterate for display operations
- Minimal memory overhead

**Alternatives Considered**:
- `dict[int, Task]`: O(1) lookups but spec doesn't require high-performance lookups
- `deque`: No significant benefit over list for our use case
- Custom data structure: Premature optimization

**Performance Analysis**:
- Lookup by ID: O(n) - acceptable for 1000 tasks (~1ms on modern hardware)
- Add task: O(1) - append operation
- Delete task: O(n) - requires search + remove
- List all: O(n) - single iteration

### 3. Task Data Model Design

**Decision**: Use Python `dataclass` with validation in `__post_init__`

**Rationale**:
- Built-in Python 3.13 feature (no external dependency)
- Automatic `__init__`, `__repr__`, `__eq__` methods
- Type hints integrated naturally
- Immutability option via `frozen=True` (not used to allow updates)
- Clean, readable syntax

**Alternatives Considered**:
- Plain class: More boilerplate, less Pythonic
- `namedtuple`: Immutable; makes updates harder
- `Pydantic`: External dependency; overkill for simple validation

**Validation Strategy**:
- Title length (1-200 chars) validated in `__post_init__`
- Description optional (None or string)
- ID assigned by TodoManager (not in Task constructor)
- Status defaults to False (incomplete)

### 4. Error Handling Strategy

**Decision**: Use custom exception classes + return values

**Rationale**:
- `TaskNotFoundError`: Explicit exception for missing ID operations
- `ValidationError`: Title length violations
- CLI layer catches exceptions and displays user-friendly messages
- Business logic layer raises exceptions (separation of concerns)

**Alternatives Considered**:
- Return `None` for errors: Ambiguous, harder to test
- Return tuples `(success, result)`: Verbose, non-Pythonic
- Only exceptions: Can be verbose for expected errors

**Exception Hierarchy**:
```
TodoAppError (base)
├── TaskNotFoundError
└── ValidationError
```

### 5. Display Formatting Approach

**Decision**: Use f-strings with manual column alignment

**Rationale**:
- No external dependencies
- Full control over format
- Easy to test (predictable string output)
- Sufficient for Phase I tabular display

**Alternatives Considered**:
- `tabulate` library: External dependency; adds complexity
- `rich` library: Heavy dependency for simple table
- Manual padding: Chosen approach, balance of simplicity and readability

**Format Specification**:
```
ID  | Status | Title                    | Description
----|--------|--------------------------|-------------
1   | [ ]    | Buy groceries            | Milk, eggs, bread
2   | [X]    | Complete Phase I         | Build console app
```

### 6. Testing Strategy

**Decision**: pytest with unit + integration test separation

**Rationale**:
- pytest standard in Python ecosystem
- Fixture support for setup/teardown
- Clear test output
- Integration with coverage tools
- Supports parametrized tests (test multiple scenarios efficiently)

**Test Coverage Plan**:
- Unit tests: Each method in isolation (models, manager, CLI parsing)
- Integration tests: Full user workflows (add → view → toggle → update → delete)
- Target: 90% coverage (constitution requirement)

**Mocking Strategy**:
- Mock `input()` for CLI tests
- Mock `print()` to capture output
- TodoManager tested with real Task objects (no mocks needed)

---

# Phase 1: Design & Implementation Structure

## Data Model Design

*See [data-model.md](./data-model.md) for complete entity definitions*

### Task Entity

**Purpose**: Represents a single todo item with all required attributes

**Attributes**:
- `id: int` - Unique identifier (assigned by TodoManager)
- `title: str` - Task heading (1-200 characters, mandatory)
- `description: str` - Detailed information (optional, empty string if not provided)
- `is_completed: bool` - Completion status (default: False)
- `created_at: datetime` - Timestamp of creation (auto-assigned)

**Validation Rules**:
- Title must be 1-200 characters (enforced in `__post_init__`)
- Description has no length limit
- ID must be positive integer (enforced by TodoManager)
- Timestamps immutable after creation

**State Transitions**:
```
[Created] → is_completed=False
   ↓
[Toggle] → is_completed=True
   ↓
[Toggle] → is_completed=False (repeatable)
   ↓
[Delete] → Removed from memory
```

## Architecture Components

### Component 1: Task Model (`src/todo_app/models.py`)

**Responsibility**: Define Task data structure and validation

**Interface**:
```python
@dataclass
class Task:
    title: str
    description: str = ""
    is_completed: bool = False
    created_at: datetime = field(default_factory=datetime.now)
    id: int = 0  # Assigned by TodoManager

    def __post_init__(self):
        # Validate title length (1-200 chars)
        pass

    def to_display_dict(self) -> dict:
        # Format for CLI display
        pass
```

**Dependencies**: Python standard library (dataclasses, datetime)

### Component 2: Todo Manager (`src/todo_app/manager.py`)

**Responsibility**: Business logic and in-memory storage management

**Interface**:
```python
class TodoManager:
    def __init__(self):
        self._tasks: list[Task] = []
        self._next_id: int = 1

    def add_task(self, title: str, description: str = "") -> Task:
        # Create task with auto-assigned ID
        # Raise ValidationError if title invalid
        pass

    def get_all_tasks(self) -> list[Task]:
        # Return all tasks (ordered by creation)
        pass

    def get_task_by_id(self, task_id: int) -> Task:
        # Raise TaskNotFoundError if not found
        pass

    def update_task(self, task_id: int, title: str = None,
                    description: str = None) -> Task:
        # Update specified fields only
        # Raise TaskNotFoundError if not found
        pass

    def toggle_task(self, task_id: int) -> Task:
        # Toggle is_completed status
        # Raise TaskNotFoundError if not found
        pass

    def delete_task(self, task_id: int) -> None:
        # Remove from memory
        # Raise TaskNotFoundError if not found
        pass
```

**Dependencies**: models.Task, custom exceptions

### Component 3: CLI Interface (`src/todo_app/cli.py`)

**Responsibility**: User interaction, command parsing, output formatting

**Interface**:
```python
class TodoCLI:
    def __init__(self, manager: TodoManager):
        self.manager = manager

    def run(self) -> None:
        # Main command loop
        pass

    def display_menu(self) -> None:
        # Show available commands
        pass

    def handle_add(self) -> None:
        # Prompt for title/description, call manager.add_task()
        pass

    def handle_list(self) -> None:
        # Call manager.get_all_tasks(), format as table
        pass

    def handle_update(self) -> None:
        # Prompt for ID and new fields, call manager.update_task()
        pass

    def handle_toggle(self) -> None:
        # Prompt for ID, call manager.toggle_task()
        pass

    def handle_delete(self) -> None:
        # Prompt for ID, call manager.delete_task()
        pass

    def format_task_table(self, tasks: list[Task]) -> str:
        # Format tasks as readable table
        pass

    def display_error(self, message: str) -> None:
        # Show error to user
        pass
```

**Dependencies**: TodoManager, models.Task

### Component 4: Application Entry Point (`src/todo_app/main.py`)

**Responsibility**: Initialize components and start CLI loop

**Interface**:
```python
def main() -> None:
    manager = TodoManager()
    cli = TodoCLI(manager)

    try:
        cli.run()
    except KeyboardInterrupt:
        print("\nExiting todo app. Goodbye!")
    except Exception as e:
        print(f"Unexpected error: {e}")

if __name__ == "__main__":
    main()
```

**Dependencies**: TodoManager, TodoCLI

## Component Interaction Flow

### Sequence: Add Task

```
User Input → CLI.handle_add()
           ↓
     Prompt for title/description
           ↓
     CLI calls manager.add_task(title, desc)
           ↓
     Manager creates Task with next_id
           ↓
     Manager validates (raises ValidationError if invalid)
           ↓
     Manager appends to _tasks list
           ↓
     Manager returns Task
           ↓
     CLI displays confirmation: "Task '[title]' added with ID [N]"
```

### Sequence: View Tasks

```
User Input → CLI.handle_list()
           ↓
     CLI calls manager.get_all_tasks()
           ↓
     Manager returns list[Task]
           ↓
     CLI calls format_task_table(tasks)
           ↓
     CLI displays formatted table
     OR displays "No tasks found." if empty
```

### Sequence: Toggle Task

```
User Input → CLI.handle_toggle()
           ↓
     Prompt for task ID
           ↓
     CLI calls manager.toggle_task(id)
           ↓
     Manager finds task (raises TaskNotFoundError if not found)
           ↓
     Manager flips is_completed boolean
           ↓
     Manager returns updated Task
           ↓
     CLI displays "Task [id] marked as Complete/Incomplete"
```

### Sequence: Delete Task

```
User Input → CLI.handle_delete()
           ↓
     Prompt for task ID
           ↓
     CLI calls manager.delete_task(id)
           ↓
     Manager finds task (raises TaskNotFoundError if not found)
           ↓
     Manager removes from _tasks list
           ↓
     CLI displays "Task [id] deleted"
```

## Implementation Quickstart

*See [quickstart.md](./quickstart.md) for detailed step-by-step implementation guide*

### Phase 1: Project Setup
1. Create project structure with UV: `uv init todo-console`
2. Configure `pyproject.toml` for Python 3.13+
3. Create `src/todo_app/` package structure
4. Create `tests/` directory with unit/integration subdirs

### Phase 2: Data Model Implementation
1. Implement `Task` dataclass in `models.py`
2. Add validation in `__post_init__`
3. Implement `to_display_dict()` helper
4. Write unit tests for Task creation and validation

### Phase 3: Business Logic Implementation
1. Implement `TodoManager` class in `manager.py`
2. Implement ID generation with `_next_id` counter
3. Implement all CRUD methods (add, get, update, toggle, delete)
4. Add error handling (TaskNotFoundError, ValidationError)
5. Write comprehensive unit tests for TodoManager

### Phase 4: CLI Interface Implementation
1. Implement `TodoCLI` class in `cli.py`
2. Implement command loop with menu display
3. Implement command handlers (add, list, update, toggle, delete, exit)
4. Implement table formatting for task display
5. Add input validation and error display
6. Write unit tests for CLI parsing (mock input/output)

### Phase 5: Integration & Testing
1. Implement `main()` in `main.py`
2. Write integration tests for complete workflows
3. Run test suite with coverage report (target 90%)
4. Manual testing of all user stories from spec
5. Fix any bugs or issues identified

### Phase 6: Documentation & Polish
1. Write README.md with setup and usage instructions
2. Add docstrings to all public functions/classes
3. Run linting (PEP 8 compliance check)
4. Final test pass with all acceptance criteria

## Non-Functional Requirements

### Performance Targets
- Application startup: <500ms
- View 1000 tasks: <1 second
- Single operation (add/update/delete/toggle): <100ms
- Memory usage: <50MB for 1000 tasks

### Code Quality Standards
- PEP 8 compliance (enforced via linting)
- Type hints on all function signatures
- Docstrings on all public functions/classes
- Test coverage ≥90%

### Error Handling Requirements
- All user-facing errors display clear messages
- No stack traces shown to users (caught and formatted)
- Invalid input handled gracefully (no crashes)
- Ctrl+C exits cleanly with goodbye message

### Usability Requirements
- Commands clearly labeled in menu
- Task list formatted for readability (aligned columns)
- Status indicators visually distinct: `[ ]` vs `[X]`
- Confirmation messages after every operation
- Empty list shows helpful message: "No tasks found."

## Migration Path (Future Phases)

### Phase I → Phase II Preparation

**Architecture decisions made for future compatibility**:

1. **Separation of Concerns**: TodoManager isolated from CLI, making it easy to:
   - Replace in-memory storage with database (Phase II)
   - Add REST API layer while reusing business logic
   - Keep CLI as alternative interface alongside web UI

2. **ID Management**: Integer IDs work for single-user but can be:
   - Extended to UUIDs for distributed systems (Phase III+)
   - Prefixed with user IDs for multi-user support (Phase II+)

3. **Task Model**: Simple dataclass can be:
   - Converted to SQLModel for ORM (Phase II)
   - Extended with relationships (user_id, category_id) without breaking structure

4. **Error Handling**: Exception-based approach compatible with:
   - HTTP error codes (Phase II REST API)
   - GraphQL errors (if chosen for Phase III)

5. **Validation Logic**: Centralized in Task model, easily:
   - Extended for API request validation (Phase II)
   - Reused across multiple interfaces (CLI, API, chatbot)

**No Premature Optimization**:
- Not adding database abstraction layers (not needed until Phase II)
- Not implementing async (not needed for CLI)
- Not adding configuration management (single deployment)
- Following constitution principle: "Smallest viable change"

## Risks & Mitigation

### Risk 1: Performance degradation with 1000+ tasks
**Likelihood**: Low
**Impact**: Medium
**Mitigation**:
- Spec requires support for 1000+ tasks
- O(n) operations acceptable for this scale
- If issues arise in testing, optimize hot paths (get_task_by_id could use dict)
- Performance tests in integration suite will catch issues early

### Risk 2: Input validation edge cases
**Likelihood**: Medium
**Impact**: Low
**Mitigation**:
- Comprehensive unit tests with boundary testing (0 chars, 1 char, 200 chars, 201 chars)
- Special character testing (quotes, newlines, unicode)
- Integration tests cover real user input scenarios

### Risk 3: Test coverage below 90% target
**Likelihood**: Low
**Impact**: High (constitutional requirement)
**Mitigation**:
- Run coverage reports incrementally during development
- Focus on business logic coverage (TodoManager = highest priority)
- Integration tests count toward coverage
- Exclude trivial code (if needed) with `# pragma: no cover`

### Risk 4: Platform incompatibility (Windows/macOS/Linux)
**Likelihood**: Low
**Impact**: Low
**Mitigation**:
- Using standard library only (cross-platform by design)
- No filesystem operations (no path separator issues)
- No shell commands (no platform-specific behavior)
- Manual testing on multiple platforms before Phase I completion

---

**Plan Status**: ✅ Complete - Ready for `/sp.tasks`

**Next Steps**:
1. Run `/sp.tasks` to generate atomic task breakdown
2. Implement tasks sequentially following task dependencies
3. Verify all acceptance criteria from spec.md

**Related Documents**:
- [spec.md](./spec.md) - Feature specification
- [data-model.md](./data-model.md) - Entity definitions
- [quickstart.md](./quickstart.md) - Implementation guide
- Constitution: `.specify/memory/constitution.md`
